{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -extract data-\n",
    "data = pd.read_csv('C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Cancer_Data.csv')\n",
    "data = data.dropna(axis=1, how='any')\n",
    "data = data.drop('diagnosis', axis=1)\n",
    "data = data.drop('id', axis=1)\n",
    "#print(data)\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -normalize-\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# -training and testing sets-\n",
    "X_train, X_test = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# -autoencoder architecture-\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# -encoder-\n",
    "input_layer = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(64, activation='relu')(input_layer)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "latent_space = layers.Dense(8, activation='relu')(encoded)\n",
    "\n",
    "# -decoder-\n",
    "decoded = layers.Dense(32, activation='relu')(latent_space)\n",
    "decoded = layers.Dense(32, activation='relu')(decoded)\n",
    "decoded = layers.Dense(64, activation='relu')(decoded)\n",
    "output_layer = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# -model-\n",
    "autoencoder = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "learning_rate = 0.01  \n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 1s 6ms/step - loss: 0.0793 - val_loss: 0.0430\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0339 - val_loss: 0.0253\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0154\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0044\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# -training-\n",
    "autoencoder.fit(X_train, X_train, epochs=200, batch_size=16, validation_data=(X_test, X_test), verbose=1)\n",
    "\n",
    "reconstructed = autoencoder.predict(X_test)\n",
    "reconstruction_errors = np.mean(np.square(X_test - reconstructed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.8989087635640466\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(X_test, reconstructed)\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies detected: 6\n",
      "Anomalous data points:\n",
      "[[0.43915945 0.41156578 0.44025983 0.28984093 0.57660016 0.33408993\n",
      "  0.4215089  0.39666998 0.40858586 0.32350463 0.16625023 0.24239745\n",
      "  0.1038496  0.09510308 0.30074447 0.2651786  0.14744949 0.22466376\n",
      "  0.45502899 0.18283515 0.34863038 0.35154584 0.31520494 0.19416044\n",
      "  0.4717031  0.17881848 0.26709265 0.35979381 0.23082988 0.1606323 ]\n",
      " [0.57357187 0.56070342 0.58952388 0.41930011 0.62173874 0.48990859\n",
      "  0.45384255 0.73011928 0.28989899 0.46925021 0.14756473 0.56351662\n",
      "  0.23766668 0.11262276 0.19825271 0.43746808 0.05388889 0.34911915\n",
      "  0.31910283 0.32804057 0.44112416 0.55170576 0.45266199 0.27349587\n",
      "  0.44925048 0.24682986 0.1942492  0.63264605 0.14705303 0.24262102]\n",
      " [0.32935775 0.11701048 0.32147053 0.19117709 0.6515302  0.23977057\n",
      "  0.2366448  0.32877734 0.46262626 0.30770851 0.15737824 0.50274045\n",
      "  0.15709372 0.07085944 0.28306761 0.22695046 0.12027778 0.54044327\n",
      "  0.13041031 0.16006799 0.2379936  0.08955224 0.21968226 0.11504621\n",
      "  0.45057122 0.10585907 0.12452077 0.34879725 0.1172876  0.11471861]\n",
      " [0.62468645 0.48224552 0.69041531 0.46723224 0.68583552 1.\n",
      "  0.87956888 0.7972167  0.93232323 0.66259478 0.29701249 0.33698727\n",
      "  0.37186072 0.20470379 0.29462556 0.49642503 0.27550505 0.49119151\n",
      "  1.         0.17592554 0.54927072 0.5250533  0.59709149 0.353372\n",
      "  0.61236215 0.57155747 0.6134984  0.86185567 0.76384782 0.29253575]\n",
      " [0.66065597 0.46838011 0.65724553 0.51770944 0.43396226 0.43316361\n",
      "  0.63542643 0.65109344 0.57828283 0.18997473 0.32319392 0.10179455\n",
      "  0.26457146 0.24486083 0.1213584  0.27659447 0.24035354 0.35309718\n",
      "  0.22693758 0.14189572 0.62789043 0.39925373 0.57218985 0.44848604\n",
      "  0.3297233  0.28127213 0.55838658 0.7233677  0.30770747 0.15381084]\n",
      " [0.25931185 0.48461278 0.27765877 0.14099682 0.59555836 0.67548003\n",
      "  0.53256795 0.42460239 0.48989899 0.68386689 0.06739091 0.27378006\n",
      "  0.06040616 0.03200983 0.18479111 0.52511491 0.1955303  0.2712635\n",
      "  0.14082287 0.31733068 0.25471363 0.76385928 0.23527068 0.1293256\n",
      "  0.75368157 1.         0.88258786 0.75945017 0.55213877 1.        ]]\n",
      "Indices of anomalies: [13 15 53 67 83 86]\n"
     ]
    }
   ],
   "source": [
    "# -threshold for anomalies-\n",
    "threshold = np.percentile(reconstruction_errors, 95)  #top 5%\n",
    "anomalies = reconstruction_errors > threshold\n",
    "print(\"Anomalies detected:\", np.sum(anomalies))\n",
    "\n",
    "anomalous_data = X_test[anomalies]\n",
    "print(\"Anomalous data points:\")\n",
    "print(anomalous_data)\n",
    "\n",
    "anomaly_indices = np.where(anomalies)[0]  \n",
    "print(\"Indices of anomalies:\", anomaly_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -plot-\n",
    "plt.hist(reconstruction_errors, bins=30)\n",
    "plt.xlabel(\"Reconstruction error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Reconstruction Error Distribution\")\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.legend()\n",
    "plt.savefig('Breast Cancer Anomaly Detection.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(anomalies, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 0 = anomaly, 1 = normal\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# -confusion matrix-\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43my_test\u001b[49m, predicted_labels)\n\u001b[0;32m      6\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcm, display_labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnomalous\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming y_test is 1 for normal and 0 for anomalous\n",
    "predicted_labels = np.where(anomalies, 0, 1)  # 0 = anomaly, 1 = normal\n",
    "\n",
    "# -confusion matrix-\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Anomalous', 'Normal'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
