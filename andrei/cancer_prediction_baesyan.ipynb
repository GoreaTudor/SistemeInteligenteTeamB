{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70eb7008-7cc8-4dba-986e-2ebc425fd6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "DataFrame Size: (569, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Helper function to load data from CSV\n",
    "def load_data_from_csv(csv_file):\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming the CSV has columns like 'id', 'label', and other features\n",
    "    return df\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file = './Cancer_Data.csv'  # Replace with your actual CSV path\n",
    "\n",
    "# Load the data from the CSV file into a DataFrame\n",
    "df = load_data_from_csv(csv_file)\n",
    "\n",
    "# Example of viewing the data\n",
    "print(df.head())\n",
    "print(f'DataFrame Size: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739e4993-8a41-4e3b-89b6-e71771c29011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Load your DataFrame (for illustration)\n",
    "# df = pd.read_csv('your_file.csv')  # Uncomment this to load your actual data\n",
    "\n",
    "# Drop the unnamed column\n",
    "df.drop(columns=['Unnamed: 32'], inplace=True)\n",
    "\n",
    "# Alternatively, if you want to drop any unnamed columns automatically\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the updated DataFrame information\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4982b5d6-5a68-4455-991a-c57a3618826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57c1fa-8970-4e81-bbfa-bc52d6166ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76113f2-9365-42f9-a328-b11c4bd37c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrei Olar\\AppData\\Local\\Temp\\ipykernel_32508\\2809301025.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Replace 'b' with 0 and 'm' with 1\n",
    "df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})\n",
    "# Step 2: Convert the column to float\n",
    "df['diagnosis'] = df['diagnosis'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8697233d-d819-4d18-963d-67b6549d699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    float64\n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 137.9 KB\n",
      "None\n",
      "Min-Max Normalized DataFrame (individual columns):\n",
      "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          1.0     0.521037      0.022658        0.545989   0.363733   \n",
      "1          1.0     0.643144      0.272574        0.615783   0.501591   \n",
      "2          1.0     0.601496      0.390260        0.595743   0.449417   \n",
      "3          1.0     0.210090      0.360839        0.233501   0.102906   \n",
      "4          1.0     0.629893      0.156578        0.630986   0.489290   \n",
      "..         ...          ...           ...             ...        ...   \n",
      "564        1.0     0.690000      0.428813        0.678668   0.566490   \n",
      "565        1.0     0.622320      0.626987        0.604036   0.474019   \n",
      "566        1.0     0.455251      0.621238        0.445788   0.303118   \n",
      "567        1.0     0.644564      0.663510        0.665538   0.475716   \n",
      "568        0.0     0.036869      0.501522        0.028540   0.015907   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0           0.593753          0.792037        0.703140             0.731113   \n",
      "1           0.289880          0.181768        0.203608             0.348757   \n",
      "2           0.514309          0.431017        0.462512             0.635686   \n",
      "3           0.811321          0.811361        0.565604             0.522863   \n",
      "4           0.430351          0.347893        0.463918             0.518390   \n",
      "..               ...               ...             ...                  ...   \n",
      "564         0.526948          0.296055        0.571462             0.690358   \n",
      "565         0.407782          0.257714        0.337395             0.486630   \n",
      "566         0.288165          0.254340        0.216753             0.263519   \n",
      "567         0.588336          0.790197        0.823336             0.755467   \n",
      "568         0.000000          0.074351        0.000000             0.000000   \n",
      "\n",
      "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.686364  ...      0.620776       0.141525         0.668310   \n",
      "1         0.379798  ...      0.606901       0.303571         0.539818   \n",
      "2         0.509596  ...      0.556386       0.360075         0.508442   \n",
      "3         0.776263  ...      0.248310       0.385928         0.241347   \n",
      "4         0.378283  ...      0.519744       0.123934         0.506948   \n",
      "..             ...  ...           ...            ...              ...   \n",
      "564       0.336364  ...      0.623266       0.383262         0.576174   \n",
      "565       0.349495  ...      0.560655       0.699094         0.520892   \n",
      "566       0.267677  ...      0.393099       0.589019         0.379949   \n",
      "567       0.675253  ...      0.633582       0.730277         0.668310   \n",
      "568       0.266162  ...      0.054287       0.489072         0.043578   \n",
      "\n",
      "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      0.450698          0.601136           0.619292         0.568610   \n",
      "1      0.435214          0.347553           0.154563         0.192971   \n",
      "2      0.374508          0.483590           0.385375         0.359744   \n",
      "3      0.094008          0.915472           0.814012         0.548642   \n",
      "4      0.341575          0.437364           0.172415         0.319489   \n",
      "..          ...               ...                ...              ...   \n",
      "564    0.452664          0.461137           0.178527         0.328035   \n",
      "565    0.379915          0.300007           0.159997         0.256789   \n",
      "566    0.230731          0.282177           0.273705         0.271805   \n",
      "567    0.402035          0.619626           0.815758         0.749760   \n",
      "568    0.020497          0.124084           0.036043         0.000000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.912027        0.598462                 0.418864  \n",
      "1                0.639175        0.233590                 0.222878  \n",
      "2                0.835052        0.403706                 0.213433  \n",
      "3                0.884880        1.000000                 0.773711  \n",
      "4                0.558419        0.157500                 0.142595  \n",
      "..                    ...             ...                      ...  \n",
      "564              0.761512        0.097575                 0.105667  \n",
      "565              0.559450        0.198502                 0.074315  \n",
      "566              0.487285        0.128721                 0.151909  \n",
      "567              0.910653        0.497142                 0.452315  \n",
      "568              0.000000        0.257441                 0.100682  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Correct way: drop the 'id' column and assign back to df\n",
    "df = df.drop(columns=['id'])  # 'inplace' is False by default\n",
    "print(df.info())\n",
    "\n",
    "# Min-Max normalization for each column\n",
    "df = df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "print(\"Min-Max Normalized DataFrame (individual columns):\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd63cff9-4c55-40b6-b105-9ad74cd2a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0        1.0     0.521037      0.022658        0.545989   0.363733   \n",
      "1        1.0     0.643144      0.272574        0.615783   0.501591   \n",
      "2        1.0     0.601496      0.390260        0.595743   0.449417   \n",
      "3        1.0     0.210090      0.360839        0.233501   0.102906   \n",
      "4        1.0     0.629893      0.156578        0.630986   0.489290   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0         0.593753          0.792037        0.703140             0.731113   \n",
      "1         0.289880          0.181768        0.203608             0.348757   \n",
      "2         0.514309          0.431017        0.462512             0.635686   \n",
      "3         0.811321          0.811361        0.565604             0.522863   \n",
      "4         0.430351          0.347893        0.463918             0.518390   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0       0.686364  ...      0.620776       0.141525         0.668310   \n",
      "1       0.379798  ...      0.606901       0.303571         0.539818   \n",
      "2       0.509596  ...      0.556386       0.360075         0.508442   \n",
      "3       0.776263  ...      0.248310       0.385928         0.241347   \n",
      "4       0.378283  ...      0.519744       0.123934         0.506948   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0    0.450698          0.601136           0.619292         0.568610   \n",
      "1    0.435214          0.347553           0.154563         0.192971   \n",
      "2    0.374508          0.483590           0.385375         0.359744   \n",
      "3    0.094008          0.915472           0.814012         0.548642   \n",
      "4    0.341575          0.437364           0.172415         0.319489   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              0.912027        0.598462                 0.418864  \n",
      "1              0.639175        0.233590                 0.222878  \n",
      "2              0.835052        0.403706                 0.213433  \n",
      "3              0.884880        1.000000                 0.773711  \n",
      "4              0.558419        0.157500                 0.142595  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec6024-525e-4846-82b1-a64c6f6ee7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30cb0e-e440-420e-b94d-5c506faa32e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d504d-b282-46d4-ba6b-981442734ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78fe2a-3dac-4173-841b-0b5dca1e7e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4a239c-8c01-451a-a28a-39c38a79e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert all columns to float to ensure consistency in numeric representation\n",
    "df = df.astype(float)\n",
    "df['diagnosis'] = df['diagnosis'].astype('category')\n",
    "\n",
    "# Step 3: Remove Dx columns from features (X) and use them as labels (y)\n",
    "label_cols = df[\"diagnosis\"]\n",
    "y = df[\"diagnosis\"]  # Labels (diagnosis column only)\n",
    "X = df.drop(columns=['diagnosis'])  # Features, excluding 'diagnosis'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ad6f71-4ded-4274-a26d-711956366e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
      "Features (X) shape: (569, 30)\n",
      "Targets (y) shape: (569,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Series name: diagnosis\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "569 non-null    category\n",
      "dtypes: category(1)\n",
      "memory usage: 825.0 bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Step 4: Split the data into features (X) and multi-label target (y)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Step 3: Select best features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k='all')  # Change 'k' as needed\n",
    "selector.fit(X, y)  # Fit the selector to the data\n",
    "\n",
    "# Step 4: Get boolean mask for selected features\n",
    "selected_features_mask = selector.get_support()  # Get boolean mask for selected features\n",
    "\n",
    "# Step 5: Get the names of the selected features\n",
    "selected_features = X.columns[selected_features_mask]  # Access the original DataFrame columns\n",
    "print(\"Selected features:\", selected_features.tolist())  # Convert to list for better readability\n",
    "\n",
    "# Step 6: Transform X using the selected features and store as a NumPy array\n",
    "X_selected = selector.transform(X)  # This returns a NumPy array\n",
    "\n",
    "# Optional: Create a DataFrame from the selected features for further analysis\n",
    "X_selected_df = pd.DataFrame(X_selected, columns=selected_features)\n",
    "\n",
    "# Display the shapes to verify\n",
    "print(\"Features (X) shape:\", X_selected_df.shape)\n",
    "print(\"Targets (y) shape:\", y.shape)\n",
    "print(y.info())\n",
    "print(X_selected_df.info())  # Use the DataFrame for checking info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300193cf-9400-4335-b12e-8d229c2c3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3e39c18-dc39-41f6-abbb-bd6d5337b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   radius_mean              569 non-null    float64 \n",
      " 1   texture_mean             569 non-null    float64 \n",
      " 2   perimeter_mean           569 non-null    float64 \n",
      " 3   area_mean                569 non-null    float64 \n",
      " 4   smoothness_mean          569 non-null    float64 \n",
      " 5   compactness_mean         569 non-null    float64 \n",
      " 6   concavity_mean           569 non-null    float64 \n",
      " 7   concave points_mean      569 non-null    float64 \n",
      " 8   symmetry_mean            569 non-null    float64 \n",
      " 9   fractal_dimension_mean   569 non-null    float64 \n",
      " 10  radius_se                569 non-null    float64 \n",
      " 11  texture_se               569 non-null    float64 \n",
      " 12  perimeter_se             569 non-null    float64 \n",
      " 13  area_se                  569 non-null    float64 \n",
      " 14  smoothness_se            569 non-null    float64 \n",
      " 15  compactness_se           569 non-null    float64 \n",
      " 16  concavity_se             569 non-null    float64 \n",
      " 17  concave points_se        569 non-null    float64 \n",
      " 18  symmetry_se              569 non-null    float64 \n",
      " 19  fractal_dimension_se     569 non-null    float64 \n",
      " 20  radius_worst             569 non-null    float64 \n",
      " 21  texture_worst            569 non-null    float64 \n",
      " 22  perimeter_worst          569 non-null    float64 \n",
      " 23  area_worst               569 non-null    float64 \n",
      " 24  smoothness_worst         569 non-null    float64 \n",
      " 25  compactness_worst        569 non-null    float64 \n",
      " 26  concavity_worst          569 non-null    float64 \n",
      " 27  concave points_worst     569 non-null    float64 \n",
      " 28  symmetry_worst           569 non-null    float64 \n",
      " 29  fractal_dimension_worst  569 non-null    float64 \n",
      " 30  diagnosis                569 non-null    category\n",
      "dtypes: category(1), float64(30)\n",
      "memory usage: 134.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_data = X.copy()\n",
    "train_data['diagnosis'] = y\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79868fbd-6a01-4c1d-b9bb-ce8b8de68066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be924a35-42bb-421d-8008-47c90f1faa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#sns.pairplot(df, hue='diagnosis')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b18e8b-18ea-4646-ac58-7ba9aef7061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the training set: 455\n",
      "Number of elements in the testing set: 114\n",
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "10      0.427801      0.457558        0.407090   0.277540         0.265686   \n",
      "170     0.252686      0.090632        0.242278   0.135992         0.452920   \n",
      "407     0.277770      0.394319        0.268399   0.157370         0.206554   \n",
      "430     0.374793      0.433548        0.402944   0.229692         0.422858   \n",
      "27      0.550381      0.356442        0.541151   0.403181         0.377088   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "10           0.145114        0.077296             0.165159       0.236364   \n",
      "170          0.154684        0.093416             0.183897       0.454040   \n",
      "407          0.195632        0.143533             0.092793       0.262626   \n",
      "430          0.623029        0.640347             0.482654       0.495455   \n",
      "27           0.267530        0.349110             0.384245       0.321717   \n",
      "\n",
      "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "10                 0.147641  ...       0.582623         0.365506    0.237122   \n",
      "170                0.201980  ...       0.096482         0.182081    0.089437   \n",
      "407                0.235468  ...       0.399520         0.205289    0.113203   \n",
      "430                0.400590  ...       0.414446         0.373475    0.159138   \n",
      "27                 0.148062  ...       0.406183         0.445690    0.299302   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "10           0.309912           0.124002         0.116534   \n",
      "170          0.444628           0.096351         0.099201   \n",
      "407          0.150895           0.161355         0.146805   \n",
      "430          0.467080           0.661398         0.720367   \n",
      "27           0.413590           0.178916         0.275240   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
      "10               0.342784        0.272620                 0.193362        1.0  \n",
      "170              0.322715        0.248768                 0.083104        0.0  \n",
      "407              0.192474        0.181944                 0.173619        0.0  \n",
      "430              0.850515        0.256456                 0.396563        1.0  \n",
      "27               0.512027        0.152967                 0.125738        1.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000000 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned structure: []\n",
      "Model nodes: []\n",
      "Series([], dtype: float64)\n",
      "Evidence for index 0: {}\n",
      "No valid evidence for index 0, skipping prediction.\n",
      "Evidence for index 1: {}\n",
      "No valid evidence for index 1, skipping prediction.\n",
      "Evidence for index 2: {}\n",
      "No valid evidence for index 2, skipping prediction.\n",
      "Evidence for index 3: {}\n",
      "No valid evidence for index 3, skipping prediction.\n",
      "Evidence for index 4: {}\n",
      "No valid evidence for index 4, skipping prediction.\n",
      "Evidence for index 5: {}\n",
      "No valid evidence for index 5, skipping prediction.\n",
      "Evidence for index 6: {}\n",
      "No valid evidence for index 6, skipping prediction.\n",
      "Evidence for index 7: {}\n",
      "No valid evidence for index 7, skipping prediction.\n",
      "Evidence for index 8: {}\n",
      "No valid evidence for index 8, skipping prediction.\n",
      "Evidence for index 9: {}\n",
      "No valid evidence for index 9, skipping prediction.\n",
      "Evidence for index 10: {}\n",
      "No valid evidence for index 10, skipping prediction.\n",
      "Evidence for index 11: {}\n",
      "No valid evidence for index 11, skipping prediction.\n",
      "Evidence for index 12: {}\n",
      "No valid evidence for index 12, skipping prediction.\n",
      "Evidence for index 13: {}\n",
      "No valid evidence for index 13, skipping prediction.\n",
      "Evidence for index 14: {}\n",
      "No valid evidence for index 14, skipping prediction.\n",
      "Evidence for index 15: {}\n",
      "No valid evidence for index 15, skipping prediction.\n",
      "Evidence for index 16: {}\n",
      "No valid evidence for index 16, skipping prediction.\n",
      "Evidence for index 17: {}\n",
      "No valid evidence for index 17, skipping prediction.\n",
      "Evidence for index 18: {}\n",
      "No valid evidence for index 18, skipping prediction.\n",
      "Evidence for index 19: {}\n",
      "No valid evidence for index 19, skipping prediction.\n",
      "Evidence for index 20: {}\n",
      "No valid evidence for index 20, skipping prediction.\n",
      "Evidence for index 21: {}\n",
      "No valid evidence for index 21, skipping prediction.\n",
      "Evidence for index 22: {}\n",
      "No valid evidence for index 22, skipping prediction.\n",
      "Evidence for index 23: {}\n",
      "No valid evidence for index 23, skipping prediction.\n",
      "Evidence for index 24: {}\n",
      "No valid evidence for index 24, skipping prediction.\n",
      "Evidence for index 25: {}\n",
      "No valid evidence for index 25, skipping prediction.\n",
      "Evidence for index 26: {}\n",
      "No valid evidence for index 26, skipping prediction.\n",
      "Evidence for index 27: {}\n",
      "No valid evidence for index 27, skipping prediction.\n",
      "Evidence for index 28: {}\n",
      "No valid evidence for index 28, skipping prediction.\n",
      "Evidence for index 29: {}\n",
      "No valid evidence for index 29, skipping prediction.\n",
      "Evidence for index 30: {}\n",
      "No valid evidence for index 30, skipping prediction.\n",
      "Evidence for index 31: {}\n",
      "No valid evidence for index 31, skipping prediction.\n",
      "Evidence for index 32: {}\n",
      "No valid evidence for index 32, skipping prediction.\n",
      "Evidence for index 33: {}\n",
      "No valid evidence for index 33, skipping prediction.\n",
      "Evidence for index 34: {}\n",
      "No valid evidence for index 34, skipping prediction.\n",
      "Evidence for index 35: {}\n",
      "No valid evidence for index 35, skipping prediction.\n",
      "Evidence for index 36: {}\n",
      "No valid evidence for index 36, skipping prediction.\n",
      "Evidence for index 37: {}\n",
      "No valid evidence for index 37, skipping prediction.\n",
      "Evidence for index 38: {}\n",
      "No valid evidence for index 38, skipping prediction.\n",
      "Evidence for index 39: {}\n",
      "No valid evidence for index 39, skipping prediction.\n",
      "Evidence for index 40: {}\n",
      "No valid evidence for index 40, skipping prediction.\n",
      "Evidence for index 41: {}\n",
      "No valid evidence for index 41, skipping prediction.\n",
      "Evidence for index 42: {}\n",
      "No valid evidence for index 42, skipping prediction.\n",
      "Evidence for index 43: {}\n",
      "No valid evidence for index 43, skipping prediction.\n",
      "Evidence for index 44: {}\n",
      "No valid evidence for index 44, skipping prediction.\n",
      "Evidence for index 45: {}\n",
      "No valid evidence for index 45, skipping prediction.\n",
      "Evidence for index 46: {}\n",
      "No valid evidence for index 46, skipping prediction.\n",
      "Evidence for index 47: {}\n",
      "No valid evidence for index 47, skipping prediction.\n",
      "Evidence for index 48: {}\n",
      "No valid evidence for index 48, skipping prediction.\n",
      "Evidence for index 49: {}\n",
      "No valid evidence for index 49, skipping prediction.\n",
      "Evidence for index 50: {}\n",
      "No valid evidence for index 50, skipping prediction.\n",
      "Evidence for index 51: {}\n",
      "No valid evidence for index 51, skipping prediction.\n",
      "Evidence for index 52: {}\n",
      "No valid evidence for index 52, skipping prediction.\n",
      "Evidence for index 53: {}\n",
      "No valid evidence for index 53, skipping prediction.\n",
      "Evidence for index 54: {}\n",
      "No valid evidence for index 54, skipping prediction.\n",
      "Evidence for index 55: {}\n",
      "No valid evidence for index 55, skipping prediction.\n",
      "Evidence for index 56: {}\n",
      "No valid evidence for index 56, skipping prediction.\n",
      "Evidence for index 57: {}\n",
      "No valid evidence for index 57, skipping prediction.\n",
      "Evidence for index 58: {}\n",
      "No valid evidence for index 58, skipping prediction.\n",
      "Evidence for index 59: {}\n",
      "No valid evidence for index 59, skipping prediction.\n",
      "Evidence for index 60: {}\n",
      "No valid evidence for index 60, skipping prediction.\n",
      "Evidence for index 61: {}\n",
      "No valid evidence for index 61, skipping prediction.\n",
      "Evidence for index 62: {}\n",
      "No valid evidence for index 62, skipping prediction.\n",
      "Evidence for index 63: {}\n",
      "No valid evidence for index 63, skipping prediction.\n",
      "Evidence for index 64: {}\n",
      "No valid evidence for index 64, skipping prediction.\n",
      "Evidence for index 65: {}\n",
      "No valid evidence for index 65, skipping prediction.\n",
      "Evidence for index 66: {}\n",
      "No valid evidence for index 66, skipping prediction.\n",
      "Evidence for index 67: {}\n",
      "No valid evidence for index 67, skipping prediction.\n",
      "Evidence for index 68: {}\n",
      "No valid evidence for index 68, skipping prediction.\n",
      "Evidence for index 69: {}\n",
      "No valid evidence for index 69, skipping prediction.\n",
      "Evidence for index 70: {}\n",
      "No valid evidence for index 70, skipping prediction.\n",
      "Evidence for index 71: {}\n",
      "No valid evidence for index 71, skipping prediction.\n",
      "Evidence for index 72: {}\n",
      "No valid evidence for index 72, skipping prediction.\n",
      "Evidence for index 73: {}\n",
      "No valid evidence for index 73, skipping prediction.\n",
      "Evidence for index 74: {}\n",
      "No valid evidence for index 74, skipping prediction.\n",
      "Evidence for index 75: {}\n",
      "No valid evidence for index 75, skipping prediction.\n",
      "Evidence for index 76: {}\n",
      "No valid evidence for index 76, skipping prediction.\n",
      "Evidence for index 77: {}\n",
      "No valid evidence for index 77, skipping prediction.\n",
      "Evidence for index 78: {}\n",
      "No valid evidence for index 78, skipping prediction.\n",
      "Evidence for index 79: {}\n",
      "No valid evidence for index 79, skipping prediction.\n",
      "Evidence for index 80: {}\n",
      "No valid evidence for index 80, skipping prediction.\n",
      "Evidence for index 81: {}\n",
      "No valid evidence for index 81, skipping prediction.\n",
      "Evidence for index 82: {}\n",
      "No valid evidence for index 82, skipping prediction.\n",
      "Evidence for index 83: {}\n",
      "No valid evidence for index 83, skipping prediction.\n",
      "Evidence for index 84: {}\n",
      "No valid evidence for index 84, skipping prediction.\n",
      "Evidence for index 85: {}\n",
      "No valid evidence for index 85, skipping prediction.\n",
      "Evidence for index 86: {}\n",
      "No valid evidence for index 86, skipping prediction.\n",
      "Evidence for index 87: {}\n",
      "No valid evidence for index 87, skipping prediction.\n",
      "Evidence for index 88: {}\n",
      "No valid evidence for index 88, skipping prediction.\n",
      "Evidence for index 89: {}\n",
      "No valid evidence for index 89, skipping prediction.\n",
      "Evidence for index 90: {}\n",
      "No valid evidence for index 90, skipping prediction.\n",
      "Evidence for index 91: {}\n",
      "No valid evidence for index 91, skipping prediction.\n",
      "Evidence for index 92: {}\n",
      "No valid evidence for index 92, skipping prediction.\n",
      "Evidence for index 93: {}\n",
      "No valid evidence for index 93, skipping prediction.\n",
      "Evidence for index 94: {}\n",
      "No valid evidence for index 94, skipping prediction.\n",
      "Evidence for index 95: {}\n",
      "No valid evidence for index 95, skipping prediction.\n",
      "Evidence for index 96: {}\n",
      "No valid evidence for index 96, skipping prediction.\n",
      "Evidence for index 97: {}\n",
      "No valid evidence for index 97, skipping prediction.\n",
      "Evidence for index 98: {}\n",
      "No valid evidence for index 98, skipping prediction.\n",
      "Evidence for index 99: {}\n",
      "No valid evidence for index 99, skipping prediction.\n",
      "Evidence for index 100: {}\n",
      "No valid evidence for index 100, skipping prediction.\n",
      "Evidence for index 101: {}\n",
      "No valid evidence for index 101, skipping prediction.\n",
      "Evidence for index 102: {}\n",
      "No valid evidence for index 102, skipping prediction.\n",
      "Evidence for index 103: {}\n",
      "No valid evidence for index 103, skipping prediction.\n",
      "Evidence for index 104: {}\n",
      "No valid evidence for index 104, skipping prediction.\n",
      "Evidence for index 105: {}\n",
      "No valid evidence for index 105, skipping prediction.\n",
      "Evidence for index 106: {}\n",
      "No valid evidence for index 106, skipping prediction.\n",
      "Evidence for index 107: {}\n",
      "No valid evidence for index 107, skipping prediction.\n",
      "Evidence for index 108: {}\n",
      "No valid evidence for index 108, skipping prediction.\n",
      "Evidence for index 109: {}\n",
      "No valid evidence for index 109, skipping prediction.\n",
      "Evidence for index 110: {}\n",
      "No valid evidence for index 110, skipping prediction.\n",
      "Evidence for index 111: {}\n",
      "No valid evidence for index 111, skipping prediction.\n",
      "Evidence for index 112: {}\n",
      "No valid evidence for index 112, skipping prediction.\n",
      "Evidence for index 113: {}\n",
      "No valid evidence for index 113, skipping prediction.\n",
      "Evaluating model performance...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_pred_valid) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true_valid):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# Calculate confusion matrix and classification report\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true_valid, y_pred_valid)\n\u001b[1;32m---> 83\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Print confusion matrix and classification report\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\mor\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\mor\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2679\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2678\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2679\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2680\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2681\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'train_data' is your original dataset that includes 'Dx' as the target variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Convert target variable and categorical features if necessary\n",
    "y_train = y_train.astype('category')\n",
    "\n",
    "# Print the number of elements in the training and testing sets\n",
    "print(f\"Number of elements in the training set: {X_train.shape[0]}\")\n",
    "print(f\"Number of elements in the testing set: {X_test.shape[0]}\")\n",
    "\n",
    "print(pd.concat([X_train, y_train], axis=1).head())\n",
    "\n",
    "hc = HillClimbSearch(pd.concat([X_train, y_train], axis=1))\n",
    "best_model = hc.estimate(scoring_method=BicScore(pd.concat([X_train, y_train], axis=1)))\n",
    "\n",
    "print(\"Learned structure:\", best_model.edges())\n",
    "\n",
    "\n",
    "# Step 3: Create Bayesian Network with learned structure\n",
    "model = BayesianNetwork(best_model.edges())\n",
    "model.fit(pd.concat([X_train, y_train], axis=1), estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Optionally check the nodes\n",
    "print(\"Model nodes:\", model.nodes())\n",
    "\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "# Step 4: Prepare the test data for predictions\n",
    "model_nodes = set(model.nodes())\n",
    "X_test_filtered = X_test.loc[:, X_test.columns.intersection(model_nodes)]\n",
    "print(X_test_filtered.isnull().sum())\n",
    "\n",
    "# Initialize predictions list\n",
    "y_pred = []\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "for i in range(len(X_test_filtered)):\n",
    "    # Filter evidence to include only model nodes and drop NaNs\n",
    "    evidence = {k: v for k, v in X_test_filtered.iloc[i].to_dict().items() if k in model_nodes and pd.notna(v)}\n",
    "\n",
    "    # Debugging: Print the evidence for the current test instance\n",
    "    print(f\"Evidence for index {i}: {evidence}\")\n",
    "\n",
    "    # Ensure evidence is not empty\n",
    "    if evidence:\n",
    "        try:\n",
    "            prediction = inference.map_query(variables=['diagnosis'], evidence=evidence)\n",
    "            y_pred.append(prediction['diagnosis'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting for index {i}: {e}\")\n",
    "            y_pred.append(None)  # Append None or a default value if prediction fails\n",
    "    else:\n",
    "        print(f\"No valid evidence for index {i}, skipping prediction.\")\n",
    "        y_pred.append(None)\n",
    "\n",
    "# Step 6: Evaluate the model performance\n",
    "if y_pred:\n",
    "    print(\"Evaluating model performance...\")\n",
    "    # Ensure the predictions and true values are of the same length\n",
    "    y_true = y_test.values  # True values from the test set\n",
    "    # Filter None values from predictions and true values\n",
    "    valid_indices = [index for index, pred in enumerate(y_pred) if pred is not None]\n",
    "    y_pred_valid = [y_pred[index] for index in valid_indices]\n",
    "    y_true_valid = [y_true[index] for index in valid_indices]\n",
    "    \n",
    "    # Ensure y_pred_valid and y_true_valid are of equal length for evaluation\n",
    "    if len(y_pred_valid) == len(y_true_valid):\n",
    "        # Calculate confusion matrix and classification report\n",
    "        cm = confusion_matrix(y_true_valid, y_pred_valid)\n",
    "        report = classification_report(y_true_valid, y_pred_valid)\n",
    "\n",
    "        # Print confusion matrix and classification report\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # Visualize the confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_true_valid, y_pred_valid)\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(\"Mismatch in lengths of predictions and true values after filtering.\")\n",
    "else:\n",
    "    print(\"No predictions were made.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafaca6-347e-4386-8720-64f3e6f1ccf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45996c26-ed20-44a6-aefe-5881cd5ed3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cce2d3-23f2-4651-bddf-208b8b86bef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774b137-16ee-4e9d-8799-0bca7b0cb837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eac5b1-5bdd-460e-a800-7c2e5400deeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b86c9d-1551-414d-a6f5-d26053b49376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9944d-c549-4027-911e-a649c0b7ae13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb946e-946a-4b23-9184-a3bfeac9c669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85a80c-dc91-43cf-84ef-b0cc079ad072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded03a4-c9d1-4bdf-a274-cd7f334c7e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8922e6-f079-41fe-9508-4faa5b72610e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dbd93-4281-402a-bacd-a5bcd4ff6009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61907bbe-e76d-4324-b1d4-b1e22a8020f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
