{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70eb7008-7cc8-4dba-986e-2ebc425fd6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "DataFrame Size: (569, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Helper function to load data from CSV\n",
    "def load_data_from_csv(csv_file):\n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming the CSV has columns like 'id', 'label', and other features\n",
    "    return df\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file = './Cancer_Data.csv'  # Replace with your actual CSV path\n",
    "\n",
    "# Load the data from the CSV file into a DataFrame\n",
    "df = load_data_from_csv(csv_file)\n",
    "\n",
    "# Example of viewing the data\n",
    "print(df.head())\n",
    "print(f'DataFrame Size: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "739e4993-8a41-4e3b-89b6-e71771c29011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Load your DataFrame (for illustration)\n",
    "# df = pd.read_csv('your_file.csv')  # Uncomment this to load your actual data\n",
    "\n",
    "# Drop the unnamed column\n",
    "df.drop(columns=['Unnamed: 32'], inplace=True)\n",
    "\n",
    "# Alternatively, if you want to drop any unnamed columns automatically\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Display the updated DataFrame information\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4982b5d6-5a68-4455-991a-c57a3618826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57c1fa-8970-4e81-bbfa-bc52d6166ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76113f2-9365-42f9-a328-b11c4bd37c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrei Olar\\AppData\\Local\\Temp\\ipykernel_23024\\2809301025.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Replace 'b' with 0 and 'm' with 1\n",
    "df['diagnosis'] = df['diagnosis'].replace({'B': 0, 'M': 1})\n",
    "# Step 2: Convert the column to float\n",
    "df['diagnosis'] = df['diagnosis'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8697233d-d819-4d18-963d-67b6549d699f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   diagnosis                569 non-null    float64\n",
      " 1   radius_mean              569 non-null    float64\n",
      " 2   texture_mean             569 non-null    float64\n",
      " 3   perimeter_mean           569 non-null    float64\n",
      " 4   area_mean                569 non-null    float64\n",
      " 5   smoothness_mean          569 non-null    float64\n",
      " 6   compactness_mean         569 non-null    float64\n",
      " 7   concavity_mean           569 non-null    float64\n",
      " 8   concave points_mean      569 non-null    float64\n",
      " 9   symmetry_mean            569 non-null    float64\n",
      " 10  fractal_dimension_mean   569 non-null    float64\n",
      " 11  radius_se                569 non-null    float64\n",
      " 12  texture_se               569 non-null    float64\n",
      " 13  perimeter_se             569 non-null    float64\n",
      " 14  area_se                  569 non-null    float64\n",
      " 15  smoothness_se            569 non-null    float64\n",
      " 16  compactness_se           569 non-null    float64\n",
      " 17  concavity_se             569 non-null    float64\n",
      " 18  concave points_se        569 non-null    float64\n",
      " 19  symmetry_se              569 non-null    float64\n",
      " 20  fractal_dimension_se     569 non-null    float64\n",
      " 21  radius_worst             569 non-null    float64\n",
      " 22  texture_worst            569 non-null    float64\n",
      " 23  perimeter_worst          569 non-null    float64\n",
      " 24  area_worst               569 non-null    float64\n",
      " 25  smoothness_worst         569 non-null    float64\n",
      " 26  compactness_worst        569 non-null    float64\n",
      " 27  concavity_worst          569 non-null    float64\n",
      " 28  concave points_worst     569 non-null    float64\n",
      " 29  symmetry_worst           569 non-null    float64\n",
      " 30  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 137.9 KB\n",
      "None\n",
      "Min-Max Normalized DataFrame (individual columns):\n",
      "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          1.0     0.521037      0.022658        0.545989   0.363733   \n",
      "1          1.0     0.643144      0.272574        0.615783   0.501591   \n",
      "2          1.0     0.601496      0.390260        0.595743   0.449417   \n",
      "3          1.0     0.210090      0.360839        0.233501   0.102906   \n",
      "4          1.0     0.629893      0.156578        0.630986   0.489290   \n",
      "..         ...          ...           ...             ...        ...   \n",
      "564        1.0     0.690000      0.428813        0.678668   0.566490   \n",
      "565        1.0     0.622320      0.626987        0.604036   0.474019   \n",
      "566        1.0     0.455251      0.621238        0.445788   0.303118   \n",
      "567        1.0     0.644564      0.663510        0.665538   0.475716   \n",
      "568        0.0     0.036869      0.501522        0.028540   0.015907   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0           0.593753          0.792037        0.703140             0.731113   \n",
      "1           0.289880          0.181768        0.203608             0.348757   \n",
      "2           0.514309          0.431017        0.462512             0.635686   \n",
      "3           0.811321          0.811361        0.565604             0.522863   \n",
      "4           0.430351          0.347893        0.463918             0.518390   \n",
      "..               ...               ...             ...                  ...   \n",
      "564         0.526948          0.296055        0.571462             0.690358   \n",
      "565         0.407782          0.257714        0.337395             0.486630   \n",
      "566         0.288165          0.254340        0.216753             0.263519   \n",
      "567         0.588336          0.790197        0.823336             0.755467   \n",
      "568         0.000000          0.074351        0.000000             0.000000   \n",
      "\n",
      "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.686364  ...      0.620776       0.141525         0.668310   \n",
      "1         0.379798  ...      0.606901       0.303571         0.539818   \n",
      "2         0.509596  ...      0.556386       0.360075         0.508442   \n",
      "3         0.776263  ...      0.248310       0.385928         0.241347   \n",
      "4         0.378283  ...      0.519744       0.123934         0.506948   \n",
      "..             ...  ...           ...            ...              ...   \n",
      "564       0.336364  ...      0.623266       0.383262         0.576174   \n",
      "565       0.349495  ...      0.560655       0.699094         0.520892   \n",
      "566       0.267677  ...      0.393099       0.589019         0.379949   \n",
      "567       0.675253  ...      0.633582       0.730277         0.668310   \n",
      "568       0.266162  ...      0.054287       0.489072         0.043578   \n",
      "\n",
      "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      0.450698          0.601136           0.619292         0.568610   \n",
      "1      0.435214          0.347553           0.154563         0.192971   \n",
      "2      0.374508          0.483590           0.385375         0.359744   \n",
      "3      0.094008          0.915472           0.814012         0.548642   \n",
      "4      0.341575          0.437364           0.172415         0.319489   \n",
      "..          ...               ...                ...              ...   \n",
      "564    0.452664          0.461137           0.178527         0.328035   \n",
      "565    0.379915          0.300007           0.159997         0.256789   \n",
      "566    0.230731          0.282177           0.273705         0.271805   \n",
      "567    0.402035          0.619626           0.815758         0.749760   \n",
      "568    0.020497          0.124084           0.036043         0.000000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.912027        0.598462                 0.418864  \n",
      "1                0.639175        0.233590                 0.222878  \n",
      "2                0.835052        0.403706                 0.213433  \n",
      "3                0.884880        1.000000                 0.773711  \n",
      "4                0.558419        0.157500                 0.142595  \n",
      "..                    ...             ...                      ...  \n",
      "564              0.761512        0.097575                 0.105667  \n",
      "565              0.559450        0.198502                 0.074315  \n",
      "566              0.487285        0.128721                 0.151909  \n",
      "567              0.910653        0.497142                 0.452315  \n",
      "568              0.000000        0.257441                 0.100682  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Correct way: drop the 'id' column and assign back to df\n",
    "df = df.drop(columns=['id'])  # 'inplace' is False by default\n",
    "print(df.info())\n",
    "\n",
    "# Min-Max normalization for each column\n",
    "df = df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "print(\"Min-Max Normalized DataFrame (individual columns):\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd63cff9-4c55-40b6-b105-9ad74cd2a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0        1.0     0.521037      0.022658        0.545989   0.363733   \n",
      "1        1.0     0.643144      0.272574        0.615783   0.501591   \n",
      "2        1.0     0.601496      0.390260        0.595743   0.449417   \n",
      "3        1.0     0.210090      0.360839        0.233501   0.102906   \n",
      "4        1.0     0.629893      0.156578        0.630986   0.489290   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0         0.593753          0.792037        0.703140             0.731113   \n",
      "1         0.289880          0.181768        0.203608             0.348757   \n",
      "2         0.514309          0.431017        0.462512             0.635686   \n",
      "3         0.811321          0.811361        0.565604             0.522863   \n",
      "4         0.430351          0.347893        0.463918             0.518390   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0       0.686364  ...      0.620776       0.141525         0.668310   \n",
      "1       0.379798  ...      0.606901       0.303571         0.539818   \n",
      "2       0.509596  ...      0.556386       0.360075         0.508442   \n",
      "3       0.776263  ...      0.248310       0.385928         0.241347   \n",
      "4       0.378283  ...      0.519744       0.123934         0.506948   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0    0.450698          0.601136           0.619292         0.568610   \n",
      "1    0.435214          0.347553           0.154563         0.192971   \n",
      "2    0.374508          0.483590           0.385375         0.359744   \n",
      "3    0.094008          0.915472           0.814012         0.548642   \n",
      "4    0.341575          0.437364           0.172415         0.319489   \n",
      "\n",
      "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0              0.912027        0.598462                 0.418864  \n",
      "1              0.639175        0.233590                 0.222878  \n",
      "2              0.835052        0.403706                 0.213433  \n",
      "3              0.884880        1.000000                 0.773711  \n",
      "4              0.558419        0.157500                 0.142595  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec6024-525e-4846-82b1-a64c6f6ee7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30cb0e-e440-420e-b94d-5c506faa32e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d504d-b282-46d4-ba6b-981442734ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78fe2a-3dac-4173-841b-0b5dca1e7e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4a239c-8c01-451a-a28a-39c38a79e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert all columns to float to ensure consistency in numeric representation\n",
    "df = df.astype(float)\n",
    "df['diagnosis'] = df['diagnosis'].astype('category')\n",
    "\n",
    "# Step 3: Remove Dx columns from features (X) and use them as labels (y)\n",
    "label_cols = df[\"diagnosis\"]\n",
    "y = df[\"diagnosis\"]  # Labels (diagnosis column only)\n",
    "X = df.drop(columns=['diagnosis'])  # Features, excluding 'diagnosis'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ad6f71-4ded-4274-a26d-711956366e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
      "Features (X) shape: (569, 30)\n",
      "Targets (y) shape: (569,)\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Series name: diagnosis\n",
      "Non-Null Count  Dtype   \n",
      "--------------  -----   \n",
      "569 non-null    category\n",
      "dtypes: category(1)\n",
      "memory usage: 825.0 bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Step 4: Split the data into features (X) and multi-label target (y)\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Step 3: Select best features based on ANOVA F-value\n",
    "selector = SelectKBest(score_func=f_classif, k='all')  # Change 'k' as needed\n",
    "selector.fit(X, y)  # Fit the selector to the data\n",
    "\n",
    "# Step 4: Get boolean mask for selected features\n",
    "selected_features_mask = selector.get_support()  # Get boolean mask for selected features\n",
    "\n",
    "# Step 5: Get the names of the selected features\n",
    "selected_features = X.columns[selected_features_mask]  # Access the original DataFrame columns\n",
    "print(\"Selected features:\", selected_features.tolist())  # Convert to list for better readability\n",
    "\n",
    "# Step 6: Transform X using the selected features and store as a NumPy array\n",
    "X_selected = selector.transform(X)  # This returns a NumPy array\n",
    "\n",
    "# Optional: Create a DataFrame from the selected features for further analysis\n",
    "X_selected_df = pd.DataFrame(X_selected, columns=selected_features)\n",
    "\n",
    "# Display the shapes to verify\n",
    "print(\"Features (X) shape:\", X_selected_df.shape)\n",
    "print(\"Targets (y) shape:\", y.shape)\n",
    "print(y.info())\n",
    "print(X_selected_df.info())  # Use the DataFrame for checking info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300193cf-9400-4335-b12e-8d229c2c3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e39c18-dc39-41f6-abbb-bd6d5337b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   radius_mean              569 non-null    float64 \n",
      " 1   texture_mean             569 non-null    float64 \n",
      " 2   perimeter_mean           569 non-null    float64 \n",
      " 3   area_mean                569 non-null    float64 \n",
      " 4   smoothness_mean          569 non-null    float64 \n",
      " 5   compactness_mean         569 non-null    float64 \n",
      " 6   concavity_mean           569 non-null    float64 \n",
      " 7   concave points_mean      569 non-null    float64 \n",
      " 8   symmetry_mean            569 non-null    float64 \n",
      " 9   fractal_dimension_mean   569 non-null    float64 \n",
      " 10  radius_se                569 non-null    float64 \n",
      " 11  texture_se               569 non-null    float64 \n",
      " 12  perimeter_se             569 non-null    float64 \n",
      " 13  area_se                  569 non-null    float64 \n",
      " 14  smoothness_se            569 non-null    float64 \n",
      " 15  compactness_se           569 non-null    float64 \n",
      " 16  concavity_se             569 non-null    float64 \n",
      " 17  concave points_se        569 non-null    float64 \n",
      " 18  symmetry_se              569 non-null    float64 \n",
      " 19  fractal_dimension_se     569 non-null    float64 \n",
      " 20  radius_worst             569 non-null    float64 \n",
      " 21  texture_worst            569 non-null    float64 \n",
      " 22  perimeter_worst          569 non-null    float64 \n",
      " 23  area_worst               569 non-null    float64 \n",
      " 24  smoothness_worst         569 non-null    float64 \n",
      " 25  compactness_worst        569 non-null    float64 \n",
      " 26  concavity_worst          569 non-null    float64 \n",
      " 27  concave points_worst     569 non-null    float64 \n",
      " 28  symmetry_worst           569 non-null    float64 \n",
      " 29  fractal_dimension_worst  569 non-null    float64 \n",
      " 30  diagnosis                569 non-null    category\n",
      "dtypes: category(1), float64(30)\n",
      "memory usage: 134.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_data = X.copy()\n",
    "train_data['diagnosis'] = y\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79868fbd-6a01-4c1d-b9bb-ce8b8de68066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be924a35-42bb-421d-8008-47c90f1faa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#sns.pairplot(df, hue='diagnosis')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b18e8b-18ea-4646-ac58-7ba9aef7061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the training set: 455\n",
      "Number of elements in the testing set: 114\n",
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "10      0.427801      0.457558        0.407090   0.277540         0.265686   \n",
      "170     0.252686      0.090632        0.242278   0.135992         0.452920   \n",
      "407     0.277770      0.394319        0.268399   0.157370         0.206554   \n",
      "430     0.374793      0.433548        0.402944   0.229692         0.422858   \n",
      "27      0.550381      0.356442        0.541151   0.403181         0.377088   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "10           0.145114        0.077296             0.165159       0.236364   \n",
      "170          0.154684        0.093416             0.183897       0.454040   \n",
      "407          0.195632        0.143533             0.092793       0.262626   \n",
      "430          0.623029        0.640347             0.482654       0.495455   \n",
      "27           0.267530        0.349110             0.384245       0.321717   \n",
      "\n",
      "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "10                 0.147641  ...       0.582623         0.365506    0.237122   \n",
      "170                0.201980  ...       0.096482         0.182081    0.089437   \n",
      "407                0.235468  ...       0.399520         0.205289    0.113203   \n",
      "430                0.400590  ...       0.414446         0.373475    0.159138   \n",
      "27                 0.148062  ...       0.406183         0.445690    0.299302   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "10           0.309912           0.124002         0.116534   \n",
      "170          0.444628           0.096351         0.099201   \n",
      "407          0.150895           0.161355         0.146805   \n",
      "430          0.467080           0.661398         0.720367   \n",
      "27           0.413590           0.178916         0.275240   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
      "10               0.342784        0.272620                 0.193362        1.0  \n",
      "170              0.322715        0.248768                 0.083104        0.0  \n",
      "407              0.192474        0.181944                 0.173619        0.0  \n",
      "430              0.850515        0.256456                 0.396563        1.0  \n",
      "27               0.512027        0.152967                 0.125738        1.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Working for n conditional variables: 0:   0%|          | 0/5 [00:00<?, ?it/s]D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "D:\\Anaconda\\envs\\mor\\Lib\\site-packages\\pgmpy\\estimators\\CITests.py:542: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  data.groupby([X, Y]).size().unstack(Y, fill_value=0), lambda_=lambda_\n",
      "Working for n conditional variables: 2:  40%|████      | 2/5 [00:15<00:22,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned structure: [('symmetry_se', 'symmetry_worst')]\n",
      "Learned structure: [('symmetry_se', 'symmetry_worst')]\n",
      "Model nodes: ['symmetry_se', 'symmetry_worst']\n",
      "symmetry_se       0\n",
      "symmetry_worst    0\n",
      "dtype: int64\n",
      "Evidence for index 0: {'symmetry_se': 0.07820678786514325, 'symmetry_worst': 0.2860240488862606}\n",
      "Error predicting for index 0: The node diagnosis is not in the digraph.\n",
      "Evidence for index 1: {'symmetry_se': 0.22693758090842572, 'symmetry_worst': 0.30770747092450224}\n",
      "Error predicting for index 1: The node diagnosis is not in the digraph.\n",
      "Evidence for index 2: {'symmetry_se': 0.16122586818258566, 'symmetry_worst': 0.313029765424798}\n",
      "Error predicting for index 2: The node diagnosis is not in the digraph.\n",
      "Evidence for index 3: {'symmetry_se': 0.09481060392863172, 'symmetry_worst': 0.2272816873644786}\n",
      "Error predicting for index 3: The node diagnosis is not in the digraph.\n",
      "Evidence for index 4: {'symmetry_se': 0.10916305510215568, 'symmetry_worst': 0.1243839936920954}\n",
      "Error predicting for index 4: The node diagnosis is not in the digraph.\n",
      "Evidence for index 5: {'symmetry_se': 0.38031181403726, 'symmetry_worst': 0.3094815690912675}\n",
      "Error predicting for index 5: The node diagnosis is not in the digraph.\n",
      "Evidence for index 6: {'symmetry_se': 0.08285022795069509, 'symmetry_worst': 0.24482554701360143}\n",
      "Error predicting for index 6: The node diagnosis is not in the digraph.\n",
      "Evidence for index 7: {'symmetry_se': 0.12084201046884671, 'symmetry_worst': 0.18174650108417112}\n",
      "Error predicting for index 7: The node diagnosis is not in the digraph.\n",
      "Evidence for index 8: {'symmetry_se': 0.12140485169133787, 'symmetry_worst': 0.23792627636507}\n",
      "Error predicting for index 8: The node diagnosis is not in the digraph.\n",
      "Evidence for index 9: {'symmetry_se': 0.28322170315753925, 'symmetry_worst': 0.3134240094618569}\n",
      "Error predicting for index 9: The node diagnosis is not in the digraph.\n",
      "Evidence for index 10: {'symmetry_se': 0.2792818146001013, 'symmetry_worst': 0.3455548984821604}\n",
      "Error predicting for index 10: The node diagnosis is not in the digraph.\n",
      "Evidence for index 11: {'symmetry_se': 0.47768334552822644, 'symmetry_worst': 0.3926670609107038}\n",
      "Error predicting for index 11: The node diagnosis is not in the digraph.\n",
      "Evidence for index 12: {'symmetry_se': 0.09101142567681655, 'symmetry_worst': 0.33372757737039227}\n",
      "Error predicting for index 12: The node diagnosis is not in the digraph.\n",
      "Evidence for index 13: {'symmetry_se': 0.15193898801148192, 'symmetry_worst': 0.28976936723832053}\n",
      "Error predicting for index 13: The node diagnosis is not in the digraph.\n",
      "Evidence for index 14: {'symmetry_se': 0.14828052006528955, 'symmetry_worst': 0.29568302779420463}\n",
      "Error predicting for index 14: The node diagnosis is not in the digraph.\n",
      "Evidence for index 15: {'symmetry_se': 0.22454550571283838, 'symmetry_worst': 0.017149615612063896}\n",
      "Error predicting for index 15: The node diagnosis is not in the digraph.\n",
      "Evidence for index 16: {'symmetry_se': 0.06075870996791805, 'symmetry_worst': 0.20185294697417705}\n",
      "Error predicting for index 16: The node diagnosis is not in the digraph.\n",
      "Evidence for index 17: {'symmetry_se': 0.1620701300163224, 'symmetry_worst': 0.11827321111768185}\n",
      "Error predicting for index 17: The node diagnosis is not in the digraph.\n",
      "Evidence for index 18: {'symmetry_se': 0.24283784544380027, 'symmetry_worst': 0.5052237334910309}\n",
      "Error predicting for index 18: The node diagnosis is not in the digraph.\n",
      "Evidence for index 19: {'symmetry_se': 0.03894861259638655, 'symmetry_worst': 0.04297260003942438}\n",
      "Error predicting for index 19: The node diagnosis is not in the digraph.\n",
      "Evidence for index 20: {'symmetry_se': 0.11057015815838352, 'symmetry_worst': 0.14902424600827913}\n",
      "Error predicting for index 20: The node diagnosis is not in the digraph.\n",
      "Evidence for index 21: {'symmetry_se': 0.07482974053019642, 'symmetry_worst': 0.22550758919771335}\n",
      "Error predicting for index 21: The node diagnosis is not in the digraph.\n",
      "Evidence for index 22: {'symmetry_se': 0.15601958687454268, 'symmetry_worst': 0.296668637886852}\n",
      "Error predicting for index 22: The node diagnosis is not in the digraph.\n",
      "Evidence for index 23: {'symmetry_se': 0.12872178758372263, 'symmetry_worst': 0.5332150601222156}\n",
      "Error predicting for index 23: The node diagnosis is not in the digraph.\n",
      "Evidence for index 24: {'symmetry_se': 0.22932965610401304, 'symmetry_worst': 0.28681253696037845}\n",
      "Error predicting for index 24: The node diagnosis is not in the digraph.\n",
      "Evidence for index 25: {'symmetry_se': 0.2601452130354027, 'symmetry_worst': 0.2937118076089099}\n",
      "Error predicting for index 25: The node diagnosis is not in the digraph.\n",
      "Evidence for index 26: {'symmetry_se': 0.19907694039511453, 'symmetry_worst': 0.1945594322885866}\n",
      "Error predicting for index 26: The node diagnosis is not in the digraph.\n",
      "Evidence for index 27: {'symmetry_se': 0.09523273484550007, 'symmetry_worst': 0.21407451212300416}\n",
      "Error predicting for index 27: The node diagnosis is not in the digraph.\n",
      "Evidence for index 28: {'symmetry_se': 0.11915348680137332, 'symmetry_worst': 0.358367829686576}\n",
      "Error predicting for index 28: The node diagnosis is not in the digraph.\n",
      "Evidence for index 29: {'symmetry_se': 0.12450047841503908, 'symmetry_worst': 0.14508180563768974}\n",
      "Error predicting for index 29: The node diagnosis is not in the digraph.\n",
      "Evidence for index 30: {'symmetry_se': 0.08411662070130016, 'symmetry_worst': 0.19436231027005715}\n",
      "Error predicting for index 30: The node diagnosis is not in the digraph.\n",
      "Evidence for index 31: {'symmetry_se': 0.11141441999212023, 'symmetry_worst': 0.15158683224916222}\n",
      "Error predicting for index 31: The node diagnosis is not in the digraph.\n",
      "Evidence for index 32: {'symmetry_se': 0.09945404401418359, 'symmetry_worst': 0.33688152966686385}\n",
      "Error predicting for index 32: The node diagnosis is not in the digraph.\n",
      "Evidence for index 33: {'symmetry_se': 0.11999774863511004, 'symmetry_worst': 0.14350482948945398}\n",
      "Error predicting for index 33: The node diagnosis is not in the digraph.\n",
      "Evidence for index 34: {'symmetry_se': 0.08918219170372037, 'symmetry_worst': 0.1068401340429726}\n",
      "Error predicting for index 34: The node diagnosis is not in the digraph.\n",
      "Evidence for index 35: {'symmetry_se': 0.07905104969887994, 'symmetry_worst': 0.16538537354622512}\n",
      "Error predicting for index 35: The node diagnosis is not in the digraph.\n",
      "Evidence for index 36: {'symmetry_se': 0.08411662070130016, 'symmetry_worst': 0.2075694855115316}\n",
      "Error predicting for index 36: The node diagnosis is not in the digraph.\n",
      "Evidence for index 37: {'symmetry_se': 0.4062025102718522, 'symmetry_worst': 0.17129903410210923}\n",
      "Error predicting for index 37: The node diagnosis is not in the digraph.\n",
      "Evidence for index 38: {'symmetry_se': 0.40578037935498396, 'symmetry_worst': 0.6114725014784153}\n",
      "Error predicting for index 38: The node diagnosis is not in the digraph.\n",
      "Evidence for index 39: {'symmetry_se': 0.19344852817020317, 'symmetry_worst': 0.3043563966095013}\n",
      "Error predicting for index 39: The node diagnosis is not in the digraph.\n",
      "Evidence for index 40: {'symmetry_se': 0.25944166150728876, 'symmetry_worst': 0.2529075497733097}\n",
      "Error predicting for index 40: The node diagnosis is not in the digraph.\n",
      "Evidence for index 41: {'symmetry_se': 0.272949850847076, 'symmetry_worst': 0.20500689927064855}\n",
      "Error predicting for index 41: The node diagnosis is not in the digraph.\n",
      "Evidence for index 42: {'symmetry_se': 0.1339280688917656, 'symmetry_worst': 0.17977528089887643}\n",
      "Error predicting for index 42: The node diagnosis is not in the digraph.\n",
      "Evidence for index 43: {'symmetry_se': 0.1308324421680644, 'symmetry_worst': 0.28247585255273017}\n",
      "Error predicting for index 43: The node diagnosis is not in the digraph.\n",
      "Evidence for index 44: {'symmetry_se': 0.1907750323633703, 'symmetry_worst': 0.13029765424797948}\n",
      "Error predicting for index 44: The node diagnosis is not in the digraph.\n",
      "Evidence for index 45: {'symmetry_se': 0.09818765126357853, 'symmetry_worst': 0.32150601222156516}\n",
      "Error predicting for index 45: The node diagnosis is not in the digraph.\n",
      "Evidence for index 46: {'symmetry_se': 0.12759610513874034, 'symmetry_worst': 0.1590774689532821}\n",
      "Error predicting for index 46: The node diagnosis is not in the digraph.\n",
      "Evidence for index 47: {'symmetry_se': 0.26746214892778747, 'symmetry_worst': 0.29863985807214666}\n",
      "Error predicting for index 47: The node diagnosis is not in the digraph.\n",
      "Evidence for index 48: {'symmetry_se': 0.26563291495469127, 'symmetry_worst': 0.25744135619948755}\n",
      "Error predicting for index 48: The node diagnosis is not in the digraph.\n",
      "Evidence for index 49: {'symmetry_se': 0.1651657567400236, 'symmetry_worst': 0.23970037453183524}\n",
      "Error predicting for index 49: The node diagnosis is not in the digraph.\n",
      "Evidence for index 50: {'symmetry_se': 0.07651826419766983, 'symmetry_worst': 0.22629607727183124}\n",
      "Error predicting for index 50: The node diagnosis is not in the digraph.\n",
      "Evidence for index 51: {'symmetry_se': 0.3191028310913491, 'symmetry_worst': 0.14705302582298443}\n",
      "Error predicting for index 51: The node diagnosis is not in the digraph.\n",
      "Evidence for index 52: {'symmetry_se': 0.042888501153824504, 'symmetry_worst': 0.13207175241474475}\n",
      "Error predicting for index 52: The node diagnosis is not in the digraph.\n",
      "Evidence for index 53: {'symmetry_se': 0.3307817864580402, 'symmetry_worst': 0.3222945002956831}\n",
      "Error predicting for index 53: The node diagnosis is not in the digraph.\n",
      "Evidence for index 54: {'symmetry_se': 0.11141441999212023, 'symmetry_worst': 0.10585452395032525}\n",
      "Error predicting for index 54: The node diagnosis is not in the digraph.\n",
      "Evidence for index 55: {'symmetry_se': 0.21188157820678782, 'symmetry_worst': 0.3370786516853933}\n",
      "Error predicting for index 55: The node diagnosis is not in the digraph.\n",
      "Evidence for index 56: {'symmetry_se': 0.07778465694827488, 'symmetry_worst': 0.2775478020894934}\n",
      "Error predicting for index 56: The node diagnosis is not in the digraph.\n",
      "Evidence for index 57: {'symmetry_se': 0.753897675465751, 'symmetry_worst': 0.31086142322097376}\n",
      "Error predicting for index 57: The node diagnosis is not in the digraph.\n",
      "Evidence for index 58: {'symmetry_se': 0.12084201046884671, 'symmetry_worst': 0.1925882121032919}\n",
      "Error predicting for index 58: The node diagnosis is not in the digraph.\n",
      "Evidence for index 59: {'symmetry_se': 0.17853323577418811, 'symmetry_worst': 0.26887443327419674}\n",
      "Error predicting for index 59: The node diagnosis is not in the digraph.\n",
      "Evidence for index 60: {'symmetry_se': 0.06990487983339899, 'symmetry_worst': 0.18785728365858473}\n",
      "Error predicting for index 60: The node diagnosis is not in the digraph.\n",
      "Evidence for index 61: {'symmetry_se': 0.27871897337761015, 'symmetry_worst': 0.45022669032130896}\n",
      "Error predicting for index 61: The node diagnosis is not in the digraph.\n",
      "Evidence for index 62: {'symmetry_se': 0.16502504643440083, 'symmetry_worst': 0.400354819633353}\n",
      "Error predicting for index 62: The node diagnosis is not in the digraph.\n",
      "Evidence for index 63: {'symmetry_se': 0.30292114594472896, 'symmetry_worst': 0.1139365267100335}\n",
      "Error predicting for index 63: The node diagnosis is not in the digraph.\n",
      "Evidence for index 64: {'symmetry_se': 0.130410311251196, 'symmetry_worst': 0.1172876010250345}\n",
      "Error predicting for index 64: The node diagnosis is not in the digraph.\n",
      "Evidence for index 65: {'symmetry_se': 0.15770811054201608, 'symmetry_worst': 0.2324068598462448}\n",
      "Error predicting for index 65: The node diagnosis is not in the digraph.\n",
      "Evidence for index 66: {'symmetry_se': 0.1976698373388867, 'symmetry_worst': 0.2937118076089099}\n",
      "Error predicting for index 66: The node diagnosis is not in the digraph.\n",
      "Evidence for index 67: {'symmetry_se': 0.08819721956436087, 'symmetry_worst': 0.3209146461659767}\n",
      "Error predicting for index 67: The node diagnosis is not in the digraph.\n",
      "Evidence for index 68: {'symmetry_se': 0.1724826926324084, 'symmetry_worst': 0.18687167356593737}\n",
      "Error predicting for index 68: The node diagnosis is not in the digraph.\n",
      "Evidence for index 69: {'symmetry_se': 0.19372994878144872, 'symmetry_worst': 0.47703528484131685}\n",
      "Error predicting for index 69: The node diagnosis is not in the digraph.\n",
      "Evidence for index 70: {'symmetry_se': 0.08242809703382675, 'symmetry_worst': 0.1584861028976937}\n",
      "Error predicting for index 70: The node diagnosis is not in the digraph.\n",
      "Evidence for index 71: {'symmetry_se': 0.12632971238813528, 'symmetry_worst': 0.40961955450423815}\n",
      "Error predicting for index 71: The node diagnosis is not in the digraph.\n",
      "Evidence for index 72: {'symmetry_se': 0.13617943378173014, 'symmetry_worst': 0.15750049280504633}\n",
      "Error predicting for index 72: The node diagnosis is not in the digraph.\n",
      "Evidence for index 73: {'symmetry_se': 0.09832836156920131, 'symmetry_worst': 0.19554504238123396}\n",
      "Error predicting for index 73: The node diagnosis is not in the digraph.\n",
      "Evidence for index 74: {'symmetry_se': 0.13012889063995045, 'symmetry_worst': 0.23851764242065845}\n",
      "Error predicting for index 74: The node diagnosis is not in the digraph.\n",
      "Evidence for index 75: {'symmetry_se': 0.26591433556593685, 'symmetry_worst': 0.1291149221368027}\n",
      "Error predicting for index 75: The node diagnosis is not in the digraph.\n",
      "Evidence for index 76: {'symmetry_se': 0.19372994878144872, 'symmetry_worst': 0.04849201655824958}\n",
      "Error predicting for index 76: The node diagnosis is not in the digraph.\n",
      "Evidence for index 77: {'symmetry_se': 0.09987617493105194, 'symmetry_worst': 0.2501478415138971}\n",
      "Error predicting for index 77: The node diagnosis is not in the digraph.\n",
      "Evidence for index 78: {'symmetry_se': 0.37820115945291827, 'symmetry_worst': 0.2598068204218411}\n",
      "Error predicting for index 78: The node diagnosis is not in the digraph.\n",
      "Evidence for index 79: {'symmetry_se': 0.16066302696009455, 'symmetry_worst': 0.19751626256652866}\n",
      "Error predicting for index 79: The node diagnosis is not in the digraph.\n",
      "Evidence for index 80: {'symmetry_se': 0.1257668711656442, 'symmetry_worst': 0.29351468559038046}\n",
      "Error predicting for index 80: The node diagnosis is not in the digraph.\n",
      "Evidence for index 81: {'symmetry_se': 0.2244047954072156, 'symmetry_worst': 0.28424995071949544}\n",
      "Error predicting for index 81: The node diagnosis is not in the digraph.\n",
      "Evidence for index 82: {'symmetry_se': 0.4180221759441661, 'symmetry_worst': 0.17149615612063868}\n",
      "Error predicting for index 82: The node diagnosis is not in the digraph.\n",
      "Evidence for index 83: {'symmetry_se': 0.16797996285247932, 'symmetry_worst': 0.2592154543662527}\n",
      "Error predicting for index 83: The node diagnosis is not in the digraph.\n",
      "Evidence for index 84: {'symmetry_se': 0.17177914110429446, 'symmetry_worst': 0.1612458111571063}\n",
      "Error predicting for index 84: The node diagnosis is not in the digraph.\n",
      "Evidence for index 85: {'symmetry_se': 0.23735014352451173, 'symmetry_worst': 0.26000394244037056}\n",
      "Error predicting for index 85: The node diagnosis is not in the digraph.\n",
      "Evidence for index 86: {'symmetry_se': 0.285332357741881, 'symmetry_worst': 0.32623694066627246}\n",
      "Error predicting for index 86: The node diagnosis is not in the digraph.\n",
      "Evidence for index 87: {'symmetry_se': 0.6085439297574154, 'symmetry_worst': 0.7098363887246205}\n",
      "Error predicting for index 87: The node diagnosis is not in the digraph.\n",
      "Evidence for index 88: {'symmetry_se': 0.1306917318624416, 'symmetry_worst': 0.33530455351862803}\n",
      "Error predicting for index 88: The node diagnosis is not in the digraph.\n",
      "Evidence for index 89: {'symmetry_se': 0.2737941126808127, 'symmetry_worst': 0.3073132268874434}\n",
      "Error predicting for index 89: The node diagnosis is not in the digraph.\n",
      "Evidence for index 90: {'symmetry_se': 0.17684471210671468, 'symmetry_worst': 0.44608712793219}\n",
      "Error predicting for index 90: The node diagnosis is not in the digraph.\n",
      "Evidence for index 91: {'symmetry_se': 0.24663702369561544, 'symmetry_worst': 0.13581707076680463}\n",
      "Error predicting for index 91: The node diagnosis is not in the digraph.\n",
      "Evidence for index 92: {'symmetry_se': 0.22018348623853207, 'symmetry_worst': 0.2020500689927065}\n",
      "Error predicting for index 92: The node diagnosis is not in the digraph.\n",
      "Evidence for index 93: {'symmetry_se': 0.06455788821973321, 'symmetry_worst': 0.15750049280504633}\n",
      "Error predicting for index 93: The node diagnosis is not in the digraph.\n",
      "Evidence for index 94: {'symmetry_se': 0.10240896043226205, 'symmetry_worst': 0.192193968066233}\n",
      "Error predicting for index 94: The node diagnosis is not in the digraph.\n",
      "Evidence for index 95: {'symmetry_se': 0.14771767884279843, 'symmetry_worst': 0.24719101123595505}\n",
      "Error predicting for index 95: The node diagnosis is not in the digraph.\n",
      "Evidence for index 96: {'symmetry_se': 0.2062531659818765, 'symmetry_worst': 0.4011433077074709}\n",
      "Error predicting for index 96: The node diagnosis is not in the digraph.\n",
      "Evidence for index 97: {'symmetry_se': 0.45502898632295824, 'symmetry_worst': 0.2308298836980091}\n",
      "Error predicting for index 97: The node diagnosis is not in the digraph.\n",
      "Evidence for index 98: {'symmetry_se': 0.2636629706759723, 'symmetry_worst': 0.3753203232801104}\n",
      "Error predicting for index 98: The node diagnosis is not in the digraph.\n",
      "Evidence for index 99: {'symmetry_se': 0.09734338942984185, 'symmetry_worst': 0.13837965700768778}\n",
      "Error predicting for index 99: The node diagnosis is not in the digraph.\n",
      "Evidence for index 100: {'symmetry_se': 0.2509990431699217, 'symmetry_worst': 0.13739404691504045}\n",
      "Error predicting for index 100: The node diagnosis is not in the digraph.\n",
      "Evidence for index 101: {'symmetry_se': 0.13603872347610738, 'symmetry_worst': 0.25349891582889816}\n",
      "Error predicting for index 101: The node diagnosis is not in the digraph.\n",
      "Evidence for index 102: {'symmetry_se': 0.15784882084763885, 'symmetry_worst': 0.2609895525330179}\n",
      "Error predicting for index 102: The node diagnosis is not in the digraph.\n",
      "Evidence for index 103: {'symmetry_se': 0.28209602071255696, 'symmetry_worst': 0.36112753794598856}\n",
      "Error predicting for index 103: The node diagnosis is not in the digraph.\n",
      "Evidence for index 104: {'symmetry_se': 0.17853323577418811, 'symmetry_worst': 0.2213680268085945}\n",
      "Error predicting for index 104: The node diagnosis is not in the digraph.\n",
      "Evidence for index 105: {'symmetry_se': 0.12520402994315302, 'symmetry_worst': 0.31914054799921154}\n",
      "Error predicting for index 105: The node diagnosis is not in the digraph.\n",
      "Evidence for index 106: {'symmetry_se': 0.11746496313389994, 'symmetry_worst': 0.3991720875221762}\n",
      "Error predicting for index 106: The node diagnosis is not in the digraph.\n",
      "Evidence for index 107: {'symmetry_se': 0.1817695728035121, 'symmetry_worst': 0.13502858269268678}\n",
      "Error predicting for index 107: The node diagnosis is not in the digraph.\n",
      "Evidence for index 108: {'symmetry_se': 0.19879551978386892, 'symmetry_worst': 0.26473487088507786}\n",
      "Error predicting for index 108: The node diagnosis is not in the digraph.\n",
      "Evidence for index 109: {'symmetry_se': 0.15362751167895536, 'symmetry_worst': 0.322688744332742}\n",
      "Error predicting for index 109: The node diagnosis is not in the digraph.\n",
      "Evidence for index 110: {'symmetry_se': 0.075111161141442, 'symmetry_worst': 0.1427163414153361}\n",
      "Error predicting for index 110: The node diagnosis is not in the digraph.\n",
      "Evidence for index 111: {'symmetry_se': 0.08524230314628241, 'symmetry_worst': 0.17859254878769956}\n",
      "Error predicting for index 111: The node diagnosis is not in the digraph.\n",
      "Evidence for index 112: {'symmetry_se': 0.10339393257162154, 'symmetry_worst': 0.3646757342795191}\n",
      "Error predicting for index 112: The node diagnosis is not in the digraph.\n",
      "Evidence for index 113: {'symmetry_se': 0.1071931108234367, 'symmetry_worst': 0.2138773901044747}\n",
      "Error predicting for index 113: The node diagnosis is not in the digraph.\n",
      "Evaluating model performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 99\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_pred_valid) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_true_valid):\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Calculate confusion matrix and classification report\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true_valid, y_pred_valid)\n\u001b[1;32m---> 99\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Print confusion matrix and classification report\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\mor\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\mor\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2679\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2678\u001b[0m     longest_last_line_heading \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted avg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2679\u001b[0m     name_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2680\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(name_width, \u001b[38;5;28mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[0;32m   2681\u001b[0m     head_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m:>\u001b[39m\u001b[38;5;132;01m{width}\u001b[39;00m\u001b[38;5;124ms} \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{:>9}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import VariableElimination\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import PC\n",
    "# Assuming 'train_data' is your original dataset that includes 'Dx' as the target variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Convert target variable and categorical features if necessary\n",
    "y_train = y_train.astype('category')\n",
    "\n",
    "# Print the number of elements in the training and testing sets\n",
    "print(f\"Number of elements in the training set: {X_train.shape[0]}\")\n",
    "print(f\"Number of elements in the testing set: {X_test.shape[0]}\")\n",
    "\n",
    "print(pd.concat([X_train, y_train], axis=1).head())\n",
    "\n",
    "#hc = HillClimbSearch\n",
    "#best_model = hc.estimate(scoring_method=BicScore(pd.concat([X_train, y_train], axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a PC object for structure learning\n",
    "pc = PC(pd.concat([X_train, y_train], axis=1))\n",
    "\n",
    "# Learn the structure using the PC algorithm\n",
    "best_model = pc.estimate(scoring_method=BicScore(pd.concat([X_train, y_train], axis=1)))\n",
    "\n",
    "# Print learned structure\n",
    "print(\"Learned structure:\", best_model.edges())\n",
    "\n",
    "\n",
    "\n",
    "print(\"Learned structure:\", best_model.edges())\n",
    "\n",
    "\n",
    "# Step 3: Create Bayesian Network with learned structure\n",
    "model = BayesianNetwork(best_model.edges())\n",
    "model.fit(pd.concat([X_train, y_train], axis=1), estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Optionally check the nodes\n",
    "print(\"Model nodes:\", model.nodes())\n",
    "\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "# Step 4: Prepare the test data for predictions\n",
    "model_nodes = set(model.nodes())\n",
    "X_test_filtered = X_test.loc[:, X_test.columns.intersection(model_nodes)]\n",
    "print(X_test_filtered.isnull().sum())\n",
    "\n",
    "# Initialize predictions list\n",
    "y_pred = []\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "for i in range(len(X_test_filtered)):\n",
    "    # Filter evidence to include only model nodes and drop NaNs\n",
    "    evidence = {k: v for k, v in X_test_filtered.iloc[i].to_dict().items() if k in model_nodes and pd.notna(v)}\n",
    "\n",
    "    # Debugging: Print the evidence for the current test instance\n",
    "    print(f\"Evidence for index {i}: {evidence}\")\n",
    "\n",
    "    # Ensure evidence is not empty\n",
    "    if evidence:\n",
    "        try:\n",
    "            prediction = inference.map_query(variables=['diagnosis'], evidence=evidence)\n",
    "            y_pred.append(prediction['diagnosis'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting for index {i}: {e}\")\n",
    "            y_pred.append(None)  # Append None or a default value if prediction fails\n",
    "    else:\n",
    "        print(f\"No valid evidence for index {i}, skipping prediction.\")\n",
    "        y_pred.append(None)\n",
    "\n",
    "# Step 6: Evaluate the model performance\n",
    "if y_pred:\n",
    "    print(\"Evaluating model performance...\")\n",
    "    # Ensure the predictions and true values are of the same length\n",
    "    y_true = y_test.values  # True values from the test set\n",
    "    # Filter None values from predictions and true values\n",
    "    valid_indices = [index for index, pred in enumerate(y_pred) if pred is not None]\n",
    "    y_pred_valid = [y_pred[index] for index in valid_indices]\n",
    "    y_true_valid = [y_true[index] for index in valid_indices]\n",
    "    \n",
    "    # Ensure y_pred_valid and y_true_valid are of equal length for evaluation\n",
    "    if len(y_pred_valid) == len(y_true_valid):\n",
    "        # Calculate confusion matrix and classification report\n",
    "        cm = confusion_matrix(y_true_valid, y_pred_valid)\n",
    "        report = classification_report(y_true_valid, y_pred_valid)\n",
    "\n",
    "        # Print confusion matrix and classification report\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(report)\n",
    "\n",
    "        # Visualize the confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_true_valid, y_pred_valid)\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "    else:\n",
    "        print(\"Mismatch in lengths of predictions and true values after filtering.\")\n",
    "else:\n",
    "    print(\"No predictions were made.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafaca6-347e-4386-8720-64f3e6f1ccf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45996c26-ed20-44a6-aefe-5881cd5ed3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cce2d3-23f2-4651-bddf-208b8b86bef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774b137-16ee-4e9d-8799-0bca7b0cb837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eac5b1-5bdd-460e-a800-7c2e5400deeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b86c9d-1551-414d-a6f5-d26053b49376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9944d-c549-4027-911e-a649c0b7ae13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb946e-946a-4b23-9184-a3bfeac9c669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85a80c-dc91-43cf-84ef-b0cc079ad072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded03a4-c9d1-4bdf-a274-cd7f334c7e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8922e6-f079-41fe-9508-4faa5b72610e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dbd93-4281-402a-bacd-a5bcd4ff6009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61907bbe-e76d-4324-b1d4-b1e22a8020f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
